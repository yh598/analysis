{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks RAG Notebook (Python Script Export)\n",
    "# Use # COMMAND ---------- as cell boundaries in Databricks.\n",
    "\n",
    "# COMMAND ----------\n",
    "CATALOG = \"development\"\n",
    "SCHEMA = \"materials_planning_analytics\"\n",
    "\n",
    "RAW_TABLE = f\"{CATALOG}.{SCHEMA}.materials_transformation_ap_v\"\n",
    "RAG_TABLE = f\"{CATALOG}.{SCHEMA}.apparel_materials_rag\"\n",
    "\n",
    "VECTOR_ENDPOINT = \"materials_vs_endpoint\"\n",
    "VECTOR_INDEX = f\"{CATALOG}.{SCHEMA}.materials_rag_index\"\n",
    "\n",
    "EMBED_MODEL = \"databricks-bge-large-en\"\n",
    "GPT_ENDPOINT = \"gpt-5.1\"\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, NumericType\n",
    "\n",
    "# COMMAND ----------\n",
    "# 1. Clean and Normalize All Columns\n",
    "df_raw = spark.table(RAW_TABLE)\n",
    "df = df_raw\n",
    "\n",
    "for c in df.columns:\n",
    "    if isinstance(df.schema[c].dataType, StringType):\n",
    "        df = df.withColumn(c, F.trim(F.col(c)))\n",
    "\n",
    "string_cols = [c for c in df.columns if isinstance(df.schema[c].dataType, StringType)]\n",
    "df = df.fillna(\"\", subset=string_cols)\n",
    "\n",
    "numeric_cols = [c for c in df.columns if isinstance(df.schema[c].dataType, NumericType)]\n",
    "for c in numeric_cols:\n",
    "    df = df.withColumn(c, F.col(c).cast(\"double\"))\n",
    "df = df.fillna(0, subset=numeric_cols)\n",
    "\n",
    "df.write.mode(\"overwrite\").saveAsTable(RAG_TABLE)\n",
    "\n",
    "# COMMAND ----------\n",
    "# 2. material_json + summary_text\n",
    "df = spark.table(RAG_TABLE)\n",
    "\n",
    "material_json_col = F.to_json(F.struct(*[F.col(c) for c in df.columns]))\n",
    "df = df.withColumn(\"material_json\", material_json_col)\n",
    "\n",
    "summary_cols = [\n",
    "    \"PRODUCT_CD\",\"STYLE_CD\",\"BOM_SEASON_CODE\",\"FISCAL_YEAR\",\"FACTORY_CD\",\"GEO_CD\",\n",
    "    \"PPG\",\"FOP\",\"DIMENSION\",\"MATERIAL_FAMILY_NM\",\"MATERIAL_INTENT_DESCRIPTION\",\n",
    "    \"MATERIAL_CONTENT\",\"WEIGHT_GRAMS_PER_SQUARE_METER\",\"MATL_GAUGE_INCH\",\n",
    "    \"CONSDRTN_AND_RISK_NM\",\"LATEST_PRICE_PER_UOM\",\"LATEST_PRICE_UOM\"\n",
    "]\n",
    "\n",
    "existing = [c for c in summary_cols if c in df.columns]\n",
    "summary_expr = F.concat_ws(\" | \", *[F.col(c).cast(\"string\") for c in existing])\n",
    "df = df.withColumn(\"summary_text\", summary_expr)\n",
    "\n",
    "df.write.mode(\"overwrite\").saveAsTable(RAG_TABLE)\n",
    "\n",
    "# COMMAND ----------\n",
    "# 3. Embeddings\n",
    "spark.sql(f\"\"\"\n",
    "ALTER TABLE {RAG_TABLE}\n",
    "ADD COLUMN IF NOT EXISTS embedding ARRAY<DOUBLE>\n",
    "\"\"\")\n",
    "\n",
    "df = spark.table(RAG_TABLE)\n",
    "df_emb = df.withColumn(\n",
    "    \"embedding\",\n",
    "    F.expr(f\"ai_embeddings('{EMBED_MODEL}', material_json)\")\n",
    ")\n",
    "df_emb.write.mode(\"overwrite\").saveAsTable(RAG_TABLE)\n",
    "\n",
    "# COMMAND ----------\n",
    "# 4. Vector Endpoint + Index\n",
    "spark.sql(\"\"\"\n",
    "CREATE VECTOR SEARCH ENDPOINT IF NOT EXISTS materials_vs_endpoint\n",
    "TYPE \"STANDARD\";\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE VECTOR SEARCH INDEX IF NOT EXISTS {VECTOR_INDEX}\n",
    "ON TABLE {RAG_TABLE}\n",
    "COLUMN embedding\n",
    "OPTIONS (\n",
    "  endpoint_name = \"{VECTOR_ENDPOINT}\",\n",
    "  metric_type = \"COSINE\"\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# COMMAND ----------\n",
    "# 5. Retrieval + GPT Reasoning\n",
    "from databricks.vector_search.client import VectorSearchClient\n",
    "from databricks.sdk import WorkspaceClient\n",
    "import pandas as pd, textwrap\n",
    "\n",
    "vsc = VectorSearchClient()\n",
    "w = WorkspaceClient()\n",
    "\n",
    "def embed_query(text: str):\n",
    "    df_emb = spark.createDataFrame([(text,)], [\"text\"])\n",
    "    return df_emb.selectExpr(\n",
    "        f\"ai_embeddings('{EMBED_MODEL}', text) AS emb\"\n",
    "    ).collect()[0][\"emb\"]\n",
    "\n",
    "def retrieve_candidates(text, k=10):\n",
    "    qvec = embed_query(text)\n",
    "    index = vsc.get_index(endpoint_name=VECTOR_ENDPOINT, index_name=VECTOR_INDEX)\n",
    "\n",
    "    res = index.similarity_search(\n",
    "        query_vector=qvec,\n",
    "        columns=[\"PRODUCT_CD\",\"STYLE_CD\",\"summary_text\",\"material_json\"],\n",
    "        k=k\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(res[\"result\"][\"data_array\"])\n",
    "    df[\"similarity\"] = res[\"result\"].get(\"scores\", [None]*len(df))\n",
    "    return df\n",
    "\n",
    "def gpt_reason(query, df):\n",
    "    table_md = df.to_markdown(index=False)\n",
    "    system_prompt = '''\n",
    "You are a senior apparel material developer.\n",
    "Provide similarity scoring, substitution recommendations,\n",
    "differences, and risk flags. Output top 3 recommended materials.\n",
    "'''\n",
    "    user_prompt = f\"User request: {query}\n",
    "\n",
    "Candidates:\n",
    "{table_md}\"\n",
    "\n",
    "    resp = w.serving_endpoints.query(\n",
    "        name=GPT_ENDPOINT,\n",
    "        inputs={\"messages\":[\n",
    "            {\"role\":\"system\",\"content\":system_prompt},\n",
    "            {\"role\":\"user\",\"content\":user_prompt}\n",
    "        ]},\n",
    "    )\n",
    "    return resp.output_text\n",
    "\n",
    "# COMMAND ----------\n",
    "# 6. Streamlit UI\n",
    "import streamlit as st\n",
    "\n",
    "st.title(\"Material Similarity & Substitution Assistant\")\n",
    "\n",
    "query = st.text_area(\"Describe your target material:\")\n",
    "k = st.slider(\"Candidates\", 3, 20, 8)\n",
    "\n",
    "if st.button(\"Search\"):\n",
    "    with st.spinner(\"Retrieving candidates...\"):\n",
    "        cands = retrieve_candidates(query, k)\n",
    "    st.dataframe(cands)\n",
    "\n",
    "    with st.spinner(\"GPT-5.1 reasoning...\"):\n",
    "        answer = gpt_reason(query, cands)\n",
    "    st.write(answer)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
